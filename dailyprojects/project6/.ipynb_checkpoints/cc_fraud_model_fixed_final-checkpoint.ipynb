{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d912b46",
   "metadata": {},
   "source": [
    "# üîç ML Data Inspection Plan\n",
    "Generated 2025-04-18 02:15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e40fd6",
   "metadata": {},
   "source": [
    "# üîç CC Fraud Data Inspection Plan (Enriched)\n",
    "Generated 2025-04-22 04:42\n",
    "\n",
    "This notebook performs a thorough exploratory data analysis (EDA) and data cleaning for the credit card fraud detection dataset. Each section includes detailed explanations, expected outputs, and next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49328db",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 1\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c23ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb608fbd",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load and Inspect Raw Data\n",
    "**Purpose:** Load the CSV file, verify its size and preview the first rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba2de9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 2\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fraud dataset\n",
    "df = pd.read_csv('/mnt/data/fraudTrain.csv')  # update path if needed\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"Memory usage before optimization:\")\n",
    "df.info(memory_usage='deep')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc106e8",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ DataFrame Memory Optimization\n",
    "**Purpose:** Downcast numeric types to reduce memory footprint.\n",
    "**Why:** Smaller memory allows faster operations and avoids swapping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a101a",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 3\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0574052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcast floats to float32 and ints to int32\n",
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "int_cols = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "df[float_cols] = df[float_cols].astype('float32')\n",
    "df[int_cols]   = df[int_cols].astype('int32')\n",
    "\n",
    "print(\"Memory usage after optimization:\")\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971350c",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Parse Transaction Timestamp & Derive Features\n",
    "**Purpose:** Convert string timestamp to datetime, extract hour/day features.\n",
    "**Why:** Time-of-day and weekday patterns can reveal fraud behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785e267",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 4\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse timestamp\n",
    "df['trans_ts'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "# Drop redundant columns\n",
    "df.drop(columns=['trans_date_trans_time', 'unix_time'], inplace=True)\n",
    "\n",
    "# Derive features\n",
    "df['hour'] = df['trans_ts'].dt.hour\n",
    "df['dow']  = df['trans_ts'].dt.dayofweek\n",
    "\n",
    "df[['trans_ts', 'hour', 'dow']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccbecb",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Drop Unnecessary ID/PII Columns\n",
    "**Purpose:** Remove columns that leak information or have no predictive value.\n",
    "**Why:** IDs and PII add noise or risk leakage but rarely generalize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba49216",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 5\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop card number, transaction ID, personal identifiers\n",
    "df.drop(columns=['Unnamed: 0','cc_num','trans_num','first','last','street','city','state','zip'], inplace=True)\n",
    "\n",
    "# Preview remaining columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae2c37",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Target Distribution (Class Imbalance)\n",
    "**Purpose:** Check fraud ratio to guide evaluation and sampling strategies.\n",
    "**Why:** Imbalanced classes require specialized metrics and handling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8403f94",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 6\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of fraud cases\n",
    "fraud_ratio = df['is_fraud'].mean()\n",
    "print(f\"Fraud cases fraction: {fraud_ratio:.6f} ({fraud_ratio*100:.3f}% )\")\n",
    "df['is_fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863b4ce",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Data Types Overview\n",
    "**Purpose:** Verify each column's type to plan preprocessing.\n",
    "**Next:** Convert object types to appropriate categories or numerics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe899dfd",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 7\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215312a",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Missing Value Summary\n",
    "**Purpose:** Identify missing data proportions.\n",
    "**Next:** Plan imputation or column removal if too many NaNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7240d9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 8\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pct = df.isna().mean().sort_values(ascending=False)\n",
    "print(missing_pct[missing_pct>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d7ef2",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Categorical Cardinality\n",
    "**Purpose:** Find high-cardinality columns to choose encoding strategy.\n",
    "**Next:** Low-card cols: one-hot; high-card: frequency/target encode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955f800",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 9\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e73603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "df[cat_cols].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfc691",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Basic Statistics & Outlier Detection\n",
    "**Purpose:** Summarize distributions, spot anomalies.\n",
    "**Next:** Winsorize or log-transform extreme outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c8faf1",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 10\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0342e",
   "metadata": {},
   "source": [
    "## üîü Detailed Class Imbalance Analysis\n",
    "**Purpose:** Evaluate false negative vs false positive costs.\n",
    "**Next:** Plan SMOTE or class weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cfdeb",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 11\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd4bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts & ratios\n",
    "counts = df['is_fraud'].value_counts()\n",
    "ratios = df['is_fraud'].value_counts(normalize=True)\n",
    "print(pd.concat([counts, ratios], axis=1, keys=['count','ratio']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd42ec",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Leakage Checks\n",
    "**Purpose:** Detect features that perfectly predict the target or leak future info.\n",
    "**Next:** Drop or re-engineer leaking features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b50794",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 12\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa530921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target for numeric features\n",
    "num_corr = df.corr()['is_fraud'].abs().sort_values(ascending=False)\n",
    "print(\"Top numeric correlations:\")\n",
    "print(num_corr.head(10))\n",
    "\n",
    "# Categorical perfect predictor check\n",
    "for col in cat_cols:\n",
    "    if df.groupby(col)['is_fraud'].nunique().eq(1).all():\n",
    "        print(f\"Potential leakage in {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fdc17f",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Duplicate Rows\n",
    "**Purpose:** Remove exact duplicates that can skew training.\n",
    "**Next:** Drop duplicates if found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d0e7a",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 13\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21652320",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_count = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {dup_count}\")\n",
    "if dup_count > 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicates dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662eb126",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Time Order & Concept Drift\n",
    "**Purpose:** Ensure chronological order and detect drift between early vs late transactions.\n",
    "**Next:** Use time-based CV or retrain triggers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5dd6c",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 14\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5010696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by transaction time\n",
    "df.sort_values('trans_ts', inplace=True)\n",
    "\n",
    "# Train-test split by time\n",
    "split_date = df['trans_ts'].quantile(0.8)\n",
    "train = df[df['trans_ts'] < split_date]\n",
    "test  = df[df['trans_ts'] >= split_date]\n",
    "\n",
    "# Compute PSI for 'amt_log' if exists\n",
    "if 'amt_log' in df.columns:\n",
    "    import numpy as np\n",
    "    def psi(expected, actual, bins=10):\n",
    "        def _bin(x, edges): return np.digitize(x, edges[:-1])\n",
    "        edges = np.histogram(expected, bins=bins)[1]\n",
    "        e_perc = np.bincount(_bin(expected, edges), minlength=bins) / len(expected)\n",
    "        a_perc = np.bincount(_bin(actual, edges), minlength=bins) / len(actual)\n",
    "        return np.sum((a_perc - e_perc) * np.log((a_perc + 1e-6)/(e_perc + 1e-6)))\n",
    "    psi_val = psi(train['amt_log'], test['amt_log'])\n",
    "    print(f\"PSI for amt_log: {psi_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f2670c",
   "metadata": {},
   "source": [
    "## üíæ Save Cleaned Data\n",
    "**Purpose:** Persist the cleaned and enriched dataset for modeling steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e02b9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 15\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('cc_fraud_cleaned.parquet', index=False)\n",
    "print(\"Cleaned data saved to 'cc_fraud_cleaned.parquet'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550e484",
   "metadata": {},
   "source": [
    "## üåü Feature Engineering Steps\n",
    "**Purpose:** Transform raw cleaned data into model-ready features.\n",
    "Each section below creates or encodes features for the fraud detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371e44c",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Handle Missing Values\n",
    "**What to do:** Impute or drop missing data.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f79e3",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 16\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values if present (example: none expected)\n",
    "# Numeric: median, Categorical: mode or 'Unknown'\n",
    "for col in df.columns:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        if df[col].dtype in ['float32','float64','int32','int64']:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna('Unknown', inplace=True)\n",
    "print(\"Missing values after imputation:\", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c956e",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Encoding Categorical Variables\n",
    "**What to do:** Convert categories into numeric representations.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0929dc",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 17\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a1f78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Binary encoding for gender\n",
    "# df['gender_enc'] = LabelEncoder().fit_transform(df['gender'])\n",
    "\n",
    "# # One-hot for low-cardinality 'category'\n",
    "# df = pd.concat([df, pd.get_dummies(df['category'], prefix='cat', drop_first=True)], axis=1)\n",
    "# df.drop(columns=['gender','category'], inplace=True)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# df['gender_enc'] = LabelEncoder().fit_transform(df['gender'])\n",
    "# df = pd.concat([df, pd.get_dummies(df['category'], drop_first=True, prefix='cat')], axis=1)\n",
    "\n",
    "# df.drop(columns=['gender', 'category'], inplace=True)\n",
    "\n",
    "\n",
    "# # Frequency encoding for 'merchant' and 'job'\n",
    "# # for col in ['merchant','job']:\n",
    "# #     freq = df[col].value_counts(normalize=True)\n",
    "# #     df[f'{col}_freq'] = df[col].map(freq)\n",
    "# #     df.drop(columns=[col], inplace=True)\n",
    "# # df.head()\n",
    "\n",
    "# for col in ['merchant', 'job']:\n",
    "#     freq = df[col].value_counts(normalize=True)\n",
    "#     df[f'{col}_freq'] = df[col].map(freq)\n",
    "\n",
    "# df.drop(columns=['merchant', 'job'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Encode high-cardinality string features\n",
    "for col in ['merchant', 'job']:\n",
    "    if col in df.columns:\n",
    "        freq_map = df[col].value_counts(normalize=True)\n",
    "        df[f'{col}_freq'] = df[col].map(freq_map)\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# 2. Encode low-cardinality features\n",
    "if 'gender' in df.columns:\n",
    "    df['gender_enc'] = LabelEncoder().fit_transform(df['gender'])\n",
    "    df.drop(columns=['gender'], inplace=True)\n",
    "\n",
    "if 'category' in df.columns:\n",
    "    df = pd.concat([df, pd.get_dummies(df['category'], prefix='cat', drop_first=True)], axis=1)\n",
    "    df.drop(columns=['category'], inplace=True)\n",
    "\n",
    "# 3. Drop datetime columns unless feature engineered\n",
    "df.drop(columns=['dob', 'trans_ts'], inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d884aa4",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Log Transform Skewed Numeric Features\n",
    "**What to do:** Reduce skew in monetary features.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7edf6",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 18\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d2f48e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness amt_log: -0.2988528\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Log transform amount\n",
    "df['amt_log'] = np.log1p(df['amt'])\n",
    "df.drop(columns=['amt'], inplace=True)\n",
    "\n",
    "# Check skew\n",
    "print(\"Skewness amt_log:\", df['amt_log'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e30e8f",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Interaction & Polynomial Features\n",
    "**What to do:** Capture nonlinear relationships.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26aacb",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 19\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "293c7ce3-c524-4416-98bb-6f211a674249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine_vectorized(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# Compute distance column\n",
    "df['dist_km'] = haversine_vectorized(df['lat'], df['long'], df['merch_lat'], df['merch_long'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b55dd79-53b8-40a0-b6b5-f5e8926e2763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'long', 'city_pop', 'merch_lat', 'merch_long', 'is_fraud',\n",
       "       'hour', 'dow', 'merchant_freq', 'job_freq', 'gender_enc',\n",
       "       'cat_food_dining', 'cat_gas_transport', 'cat_grocery_net',\n",
       "       'cat_grocery_pos', 'cat_health_fitness', 'cat_home', 'cat_kids_pets',\n",
       "       'cat_misc_net', 'cat_misc_pos', 'cat_personal_care', 'cat_shopping_net',\n",
       "       'cat_shopping_pos', 'cat_travel', 'amt_log', 'dist_km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a65e074c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dob'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/mlearn_poc/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'dob'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Convert dob to datetime if not already\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mdob\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdob\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Calculate age at the time of transaction\u001b[39;00m\n\u001b[32m      5\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m] = (df[\u001b[33m'\u001b[39m\u001b[33mtrans_ts\u001b[39m\u001b[33m'\u001b[39m] - df[\u001b[33m'\u001b[39m\u001b[33mdob\u001b[39m\u001b[33m'\u001b[39m]).dt.days // \u001b[32m365\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/mlearn_poc/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/mlearn_poc/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'dob'"
     ]
    }
   ],
   "source": [
    "# Convert dob to datetime if not already\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "\n",
    "# Calculate age at the time of transaction\n",
    "df['age'] = (df['trans_ts'] - df['dob']).dt.days // 365\n",
    "\n",
    "# Interaction: amount x distance\n",
    "df['amt_dist'] = df['amt_log'] * df['dist_km']\n",
    "\n",
    "# Polynomial: squared terms\n",
    "for col in ['amt_log', 'dist_km', 'age']:\n",
    "    df[f'{col}_sq'] = df[col] ** 2\n",
    "\n",
    "df[['amt_dist','amt_log_sq','dist_km_sq','age_sq']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb97fa",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Feature Scaling\n",
    "**What to do:** Standardize features for linear models or distance-based methods.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c3295",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 20\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scale_cols = ['amt_log','dist_km','age','hour','dow','amt_dist','amt_log_sq','dist_km_sq','age_sq']\n",
    "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "\n",
    "df[scale_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ceeb64",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Feature Matrix\n",
    "**Purpose:** Review final columns and prepare X, y for modeling.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921be7a9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 21\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10b240ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amt           float32\n",
      "lat           float32\n",
      "long          float32\n",
      "city_pop        int32\n",
      "merch_lat     float32\n",
      "merch_long    float32\n",
      "hour            int32\n",
      "dow             int32\n",
      "dtype: object\n",
      "(1296675, 8)\n",
      "Final feature matrix shape: (1296675, 8)\n",
      "Features: ['amt', 'lat', 'long', 'city_pop', 'merch_lat', 'merch_long', 'hour', 'dow']\n"
     ]
    }
   ],
   "source": [
    "# Drop any remaining raw columns if needed\n",
    "# Prepare X and y\n",
    "import numpy as np\n",
    "# Keep only numeric columns\n",
    "X = df.select_dtypes(include=['number']).drop(columns=['is_fraud'])\n",
    "\n",
    "X.select_dtypes(exclude=['number']).columns\n",
    "# Fill missing or problematic values\n",
    "X = X.fillna(0)\n",
    "X = X.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Confirm shape and types\n",
    "print(X.dtypes)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n",
    "# X = df.drop(columns=['trans_ts','is_fraud','lat','long','merch_lat','merch_long','dob'])\n",
    "# y = df['is_fraud']\n",
    "print(\"Final feature matrix shape:\", X.shape)\n",
    "print(\"Features:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf345e9",
   "metadata": {},
   "source": [
    "# üöÄ Model Development & Evaluation\n",
    "This section builds, tunes, and evaluates a fraud detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fedc31",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Model Cell 1\n",
    "**Purpose**: Load the cleaned feature set saved previously.\n",
    "**Expectation**: X should be feature matrix, y target.\n",
    "**Next**: Split into train/test.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b1ad241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1037340, 14) (259335, 14) 0.00578884454470087\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_parquet(r'/Users/shiva/PycharmProjects/mlearn_poc/dailyprojects/project8/cc_fraud_cleaned.parquet')\n",
    "X = df.drop(columns=['is_fraud'])\n",
    "y = df['is_fraud']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e97c7",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Model Cell 2\n",
    "**Purpose**: Construct pipeline with SMOTE (over-sampling) and RandomForest with class_weight.\n",
    "**Why**: Handle extreme imbalance and leverage tree robustness.\n",
    "**Alternatives**: Use XGBoost; try undersampling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c757cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35935f68",
   "metadata": {},
   "source": [
    "### ‚úÖ Data Cleanup: Encode non-numeric columns and remove datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301731d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode high-cardinality string features using frequency\n",
    "for col in ['merchant', 'job']:\n",
    "    if col in df.columns:\n",
    "        freq_map = df[col].value_counts(normalize=True)\n",
    "        df[f'{col}_freq'] = df[col].map(freq_map)\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# Encode low-cardinality features\n",
    "if 'gender' in df.columns:\n",
    "    df['gender_enc'] = LabelEncoder().fit_transform(df['gender'])\n",
    "    df.drop(columns=['gender'], inplace=True)\n",
    "\n",
    "if 'category' in df.columns:\n",
    "    df = pd.concat([df, pd.get_dummies(df['category'], prefix='cat', drop_first=True)], axis=1)\n",
    "    df.drop(columns=['category'], inplace=True)\n",
    "\n",
    "# Drop datetime columns\n",
    "df.drop(columns=['dob', 'trans_ts'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4406f",
   "metadata": {},
   "source": [
    "### üßÆ Prepare Final Numeric Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb779e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.select_dtypes(include=['number']).drop(columns=['is_fraud'])\n",
    "y = df['is_fraud']\n",
    "\n",
    "# Final check\n",
    "assert X.select_dtypes(exclude=['number']).shape[1] == 0\n",
    "assert X.isna().sum().sum() == 0\n",
    "assert y.nunique() == 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b3f550",
   "metadata": {},
   "source": [
    "### üöÄ Model Pipeline with SMOTE + RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422824bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb1b27e",
   "metadata": {},
   "source": [
    "### üîç Hyperparameter Tuning using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b67dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_dist = {\n",
    "    'rf__n_estimators': randint(300, 1000),\n",
    "    'rf__max_depth': randint(5, 20),\n",
    "    'rf__min_samples_split': randint(2, 10),\n",
    "    'rf__min_samples_leaf': randint(1, 5),\n",
    "    'rf__max_features': uniform(0.2, 0.6)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='average_precision',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    error_score='raise'  # for debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538060f8",
   "metadata": {},
   "source": [
    "### üîÅ Fit the Model (may take a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train, y_train)\n",
    "print(\"Best PR-AUC:\", search.best_score_)\n",
    "print(\"Best params:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24ba81",
   "metadata": {},
   "source": [
    "### üìä Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Test PR-AUC:\", average_precision_score(y_test, y_proba))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
