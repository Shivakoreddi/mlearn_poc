{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d912b46",
   "metadata": {},
   "source": [
    "# üîç ML Data Inspection Plan\n",
    "Generated 2025-04-18 02:15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657cb4be",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Data Snapshot and Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04a615",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Target Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92783074",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Data Types Snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e561f4",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Missing Value Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d9e87",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Categorical Column Cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ca3bd",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Basic Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e849639",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Class Imbalance Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb4e1e",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Leakage Probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14cc280",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Duplicates and Redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074df094",
   "metadata": {},
   "source": [
    "## üîü Time Order, Train-Test Split, and Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e40fd6",
   "metadata": {},
   "source": [
    "# üîç CC Fraud Data Inspection Plan (Enriched)\n",
    "Generated 2025-04-22 04:42\n",
    "\n",
    "This notebook performs a thorough exploratory data analysis (EDA) and data cleaning for the credit card fraud detection dataset. Each section includes detailed explanations, expected outputs, and next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49328db",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 1\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c23ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb608fbd",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load and Inspect Raw Data\n",
    "**Purpose:** Load the CSV file, verify its size and preview the first rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba2de9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 2\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fraud dataset\n",
    "df = pd.read_csv('/mnt/data/fraudTrain.csv')  # update path if needed\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"Memory usage before optimization:\")\n",
    "df.info(memory_usage='deep')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc106e8",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ DataFrame Memory Optimization\n",
    "**Purpose:** Downcast numeric types to reduce memory footprint.\n",
    "**Why:** Smaller memory allows faster operations and avoids swapping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a101a",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 3\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0574052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcast floats to float32 and ints to int32\n",
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "int_cols = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "df[float_cols] = df[float_cols].astype('float32')\n",
    "df[int_cols]   = df[int_cols].astype('int32')\n",
    "\n",
    "print(\"Memory usage after optimization:\")\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971350c",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Parse Transaction Timestamp & Derive Features\n",
    "**Purpose:** Convert string timestamp to datetime, extract hour/day features.\n",
    "**Why:** Time-of-day and weekday patterns can reveal fraud behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785e267",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 4\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse timestamp\n",
    "df['trans_ts'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "# Drop redundant columns\n",
    "df.drop(columns=['trans_date_trans_time', 'unix_time'], inplace=True)\n",
    "\n",
    "# Derive features\n",
    "df['hour'] = df['trans_ts'].dt.hour\n",
    "df['dow']  = df['trans_ts'].dt.dayofweek\n",
    "\n",
    "df[['trans_ts', 'hour', 'dow']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccbecb",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Drop Unnecessary ID/PII Columns\n",
    "**Purpose:** Remove columns that leak information or have no predictive value.\n",
    "**Why:** IDs and PII add noise or risk leakage but rarely generalize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba49216",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 5\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop card number, transaction ID, personal identifiers\n",
    "df.drop(columns=['Unnamed: 0','cc_num','trans_num','first','last','street','city','state','zip'], inplace=True)\n",
    "\n",
    "# Preview remaining columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae2c37",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Target Distribution (Class Imbalance)\n",
    "**Purpose:** Check fraud ratio to guide evaluation and sampling strategies.\n",
    "**Why:** Imbalanced classes require specialized metrics and handling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8403f94",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 6\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of fraud cases\n",
    "fraud_ratio = df['is_fraud'].mean()\n",
    "print(f\"Fraud cases fraction: {fraud_ratio:.6f} ({fraud_ratio*100:.3f}% )\")\n",
    "df['is_fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863b4ce",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Data Types Overview\n",
    "**Purpose:** Verify each column's type to plan preprocessing.\n",
    "**Next:** Convert object types to appropriate categories or numerics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe899dfd",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 7\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215312a",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Missing Value Summary\n",
    "**Purpose:** Identify missing data proportions.\n",
    "**Next:** Plan imputation or column removal if too many NaNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7240d9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 8\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pct = df.isna().mean().sort_values(ascending=False)\n",
    "print(missing_pct[missing_pct>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d7ef2",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Categorical Cardinality\n",
    "**Purpose:** Find high-cardinality columns to choose encoding strategy.\n",
    "**Next:** Low-card cols: one-hot; high-card: frequency/target encode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955f800",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 9\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e73603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "df[cat_cols].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfc691",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Basic Statistics & Outlier Detection\n",
    "**Purpose:** Summarize distributions, spot anomalies.\n",
    "**Next:** Winsorize or log-transform extreme outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c8faf1",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 10\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0342e",
   "metadata": {},
   "source": [
    "## üîü Detailed Class Imbalance Analysis\n",
    "**Purpose:** Evaluate false negative vs false positive costs.\n",
    "**Next:** Plan SMOTE or class weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cfdeb",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 11\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd4bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts & ratios\n",
    "counts = df['is_fraud'].value_counts()\n",
    "ratios = df['is_fraud'].value_counts(normalize=True)\n",
    "print(pd.concat([counts, ratios], axis=1, keys=['count','ratio']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd42ec",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Leakage Checks\n",
    "**Purpose:** Detect features that perfectly predict the target or leak future info.\n",
    "**Next:** Drop or re-engineer leaking features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b50794",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 12\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa530921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target for numeric features\n",
    "num_corr = df.corr()['is_fraud'].abs().sort_values(ascending=False)\n",
    "print(\"Top numeric correlations:\")\n",
    "print(num_corr.head(10))\n",
    "\n",
    "# Categorical perfect predictor check\n",
    "for col in cat_cols:\n",
    "    if df.groupby(col)['is_fraud'].nunique().eq(1).all():\n",
    "        print(f\"Potential leakage in {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fdc17f",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Duplicate Rows\n",
    "**Purpose:** Remove exact duplicates that can skew training.\n",
    "**Next:** Drop duplicates if found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d0e7a",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 13\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21652320",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_count = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {dup_count}\")\n",
    "if dup_count > 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicates dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662eb126",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Time Order & Concept Drift\n",
    "**Purpose:** Ensure chronological order and detect drift between early vs late transactions.\n",
    "**Next:** Use time-based CV or retrain triggers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5dd6c",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 14\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5010696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by transaction time\n",
    "df.sort_values('trans_ts', inplace=True)\n",
    "\n",
    "# Train-test split by time\n",
    "split_date = df['trans_ts'].quantile(0.8)\n",
    "train = df[df['trans_ts'] < split_date]\n",
    "test  = df[df['trans_ts'] >= split_date]\n",
    "\n",
    "# Compute PSI for 'amt_log' if exists\n",
    "if 'amt_log' in df.columns:\n",
    "    import numpy as np\n",
    "    def psi(expected, actual, bins=10):\n",
    "        def _bin(x, edges): return np.digitize(x, edges[:-1])\n",
    "        edges = np.histogram(expected, bins=bins)[1]\n",
    "        e_perc = np.bincount(_bin(expected, edges), minlength=bins) / len(expected)\n",
    "        a_perc = np.bincount(_bin(actual, edges), minlength=bins) / len(actual)\n",
    "        return np.sum((a_perc - e_perc) * np.log((a_perc + 1e-6)/(e_perc + 1e-6)))\n",
    "    psi_val = psi(train['amt_log'], test['amt_log'])\n",
    "    print(f\"PSI for amt_log: {psi_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f2670c",
   "metadata": {},
   "source": [
    "## üíæ Save Cleaned Data\n",
    "**Purpose:** Persist the cleaned and enriched dataset for modeling steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e02b9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 15\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('cc_fraud_cleaned.parquet', index=False)\n",
    "print(\"Cleaned data saved to 'cc_fraud_cleaned.parquet'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550e484",
   "metadata": {},
   "source": [
    "## üåü Feature Engineering Steps\n",
    "**Purpose:** Transform raw cleaned data into model-ready features.\n",
    "Each section below creates or encodes features for the fraud detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371e44c",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Handle Missing Values\n",
    "**What to do:** Impute or drop missing data.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f79e3",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 16\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values if present (example: none expected)\n",
    "# Numeric: median, Categorical: mode or 'Unknown'\n",
    "for col in df.columns:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        if df[col].dtype in ['float32','float64','int32','int64']:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna('Unknown', inplace=True)\n",
    "print(\"Missing values after imputation:\", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c956e",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Encoding Categorical Variables\n",
    "**What to do:** Convert categories into numeric representations.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0929dc",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 17\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Binary encoding for gender\n",
    "df['gender_enc'] = LabelEncoder().fit_transform(df['gender'])\n",
    "\n",
    "# One-hot for low-cardinality 'category'\n",
    "df = pd.concat([df, pd.get_dummies(df['category'], prefix='cat', drop_first=True)], axis=1)\n",
    "df.drop(columns=['gender','category'], inplace=True)\n",
    "\n",
    "# Frequency encoding for 'merchant' and 'job'\n",
    "for col in ['merchant','job']:\n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    df[f'{col}_freq'] = df[col].map(freq)\n",
    "    df.drop(columns=[col], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d884aa4",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Log Transform Skewed Numeric Features\n",
    "**What to do:** Reduce skew in monetary features.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7edf6",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 18\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Log transform amount\n",
    "df['amt_log'] = np.log1p(df['amt'])\n",
    "df.drop(columns=['amt'], inplace=True)\n",
    "\n",
    "# Check skew\n",
    "print(\"Skewness amt_log:\", df['amt_log'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e30e8f",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Interaction & Polynomial Features\n",
    "**What to do:** Capture nonlinear relationships.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26aacb",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 19\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction: amount x distance\n",
    "df['amt_dist'] = df['amt_log'] * df['dist_km']\n",
    "\n",
    "# Polynomial: squared terms\n",
    "for col in ['amt_log', 'dist_km', 'age']:\n",
    "    df[f'{col}_sq'] = df[col] ** 2\n",
    "\n",
    "df[['amt_dist','amt_log_sq','dist_km_sq','age_sq']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb97fa",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Feature Scaling\n",
    "**What to do:** Standardize features for linear models or distance-based methods.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c3295",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 20\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scale_cols = ['amt_log','dist_km','age','hour','dow','amt_dist','amt_log_sq','dist_km_sq','age_sq']\n",
    "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "\n",
    "df[scale_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ceeb64",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Feature Matrix\n",
    "**Purpose:** Review final columns and prepare X, y for modeling.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921be7a9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 21\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b240ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any remaining raw columns if needed\n",
    "# Prepare X and y\n",
    "X = df.drop(columns=['trans_ts','is_fraud','lat','long','merch_lat','merch_long','dob'])\n",
    "y = df['is_fraud']\n",
    "print(\"Final feature matrix shape:\", X.shape)\n",
    "print(\"Features:\", X.columns.tolist())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
