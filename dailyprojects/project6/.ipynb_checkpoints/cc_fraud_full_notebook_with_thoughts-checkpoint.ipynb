{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d912b46",
   "metadata": {},
   "source": [
    "# üîç ML Data Inspection Plan\n",
    "Generated 2025-04-18 02:15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657cb4be",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Data Snapshot and Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04a615",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Target Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92783074",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Data Types Snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e561f4",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Missing Value Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d9e87",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Categorical Column Cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ca3bd",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Basic Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e849639",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Class Imbalance Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb4e1e",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Leakage Probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14cc280",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Duplicates and Redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074df094",
   "metadata": {},
   "source": [
    "## üîü Time Order, Train-Test Split, and Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e40fd6",
   "metadata": {},
   "source": [
    "# üîç CC Fraud Data Inspection Plan (Enriched)\n",
    "Generated 2025-04-22 04:42\n",
    "\n",
    "This notebook performs a thorough exploratory data analysis (EDA) and data cleaning for the credit card fraud detection dataset. Each section includes detailed explanations, expected outputs, and next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49328db",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 1\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c23ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb608fbd",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load and Inspect Raw Data\n",
    "**Purpose:** Load the CSV file, verify its size and preview the first rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba2de9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 2\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1bc3193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1296675, 23)\n",
      "Memory usage before optimization:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1296675 non-null  int64  \n",
      " 1   trans_date_trans_time  1296675 non-null  object \n",
      " 2   cc_num                 1296675 non-null  int64  \n",
      " 3   merchant               1296675 non-null  object \n",
      " 4   category               1296675 non-null  object \n",
      " 5   amt                    1296675 non-null  float64\n",
      " 6   first                  1296675 non-null  object \n",
      " 7   last                   1296675 non-null  object \n",
      " 8   gender                 1296675 non-null  object \n",
      " 9   street                 1296675 non-null  object \n",
      " 10  city                   1296675 non-null  object \n",
      " 11  state                  1296675 non-null  object \n",
      " 12  zip                    1296675 non-null  int64  \n",
      " 13  lat                    1296675 non-null  float64\n",
      " 14  long                   1296675 non-null  float64\n",
      " 15  city_pop               1296675 non-null  int64  \n",
      " 16  job                    1296675 non-null  object \n",
      " 17  dob                    1296675 non-null  object \n",
      " 18  trans_num              1296675 non-null  object \n",
      " 19  unix_time              1296675 non-null  int64  \n",
      " 20  merch_lat              1296675 non-null  float64\n",
      " 21  merch_long             1296675 non-null  float64\n",
      " 22  is_fraud               1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 1.0 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "0           0   2019-01-01 00:00:18  2703186189652095   \n",
       "1           1   2019-01-01 00:00:44      630423337322   \n",
       "2           2   2019-01-01 00:00:51    38859492057661   \n",
       "3           3   2019-01-01 00:01:16  3534093764340240   \n",
       "4           4   2019-01-01 00:03:06   375534208663984   \n",
       "\n",
       "                             merchant       category     amt      first  \\\n",
       "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
       "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
       "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
       "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
       "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
       "\n",
       "      last gender                        street  ...      lat      long  \\\n",
       "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
       "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
       "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
       "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
       "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
       "\n",
       "   city_pop                                job         dob  \\\n",
       "0      3495          Psychologist, counselling  1988-03-09   \n",
       "1       149  Special educational needs teacher  1978-06-21   \n",
       "2      4154        Nature conservation officer  1962-01-19   \n",
       "3      1939                    Patent attorney  1967-01-12   \n",
       "4        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load fraud dataset\n",
    "df = pd.read_csv(r'/Users/shiva/PycharmProjects/mlearn_poc/dailyprojects/project8/fraudTrain.csv')  # update path if needed\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"Memory usage before optimization:\")\n",
    "df.info(memory_usage='deep')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc106e8",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ DataFrame Memory Optimization\n",
    "**Purpose:** Downcast numeric types to reduce memory footprint.\n",
    "**Why:** Smaller memory allows faster operations and avoids swapping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a101a",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 3\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0574052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1296675 non-null  int32  \n",
      " 1   trans_date_trans_time  1296675 non-null  object \n",
      " 2   cc_num                 1296675 non-null  int32  \n",
      " 3   merchant               1296675 non-null  object \n",
      " 4   category               1296675 non-null  object \n",
      " 5   amt                    1296675 non-null  float32\n",
      " 6   first                  1296675 non-null  object \n",
      " 7   last                   1296675 non-null  object \n",
      " 8   gender                 1296675 non-null  object \n",
      " 9   street                 1296675 non-null  object \n",
      " 10  city                   1296675 non-null  object \n",
      " 11  state                  1296675 non-null  object \n",
      " 12  zip                    1296675 non-null  int32  \n",
      " 13  lat                    1296675 non-null  float32\n",
      " 14  long                   1296675 non-null  float32\n",
      " 15  city_pop               1296675 non-null  int32  \n",
      " 16  job                    1296675 non-null  object \n",
      " 17  dob                    1296675 non-null  object \n",
      " 18  trans_num              1296675 non-null  object \n",
      " 19  unix_time              1296675 non-null  int32  \n",
      " 20  merch_lat              1296675 non-null  float32\n",
      " 21  merch_long             1296675 non-null  float32\n",
      " 22  is_fraud               1296675 non-null  int32  \n",
      "dtypes: float32(5), int32(6), object(12)\n",
      "memory usage: 980.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Downcast floats to float32 and ints to int32\n",
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "int_cols = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "df[float_cols] = df[float_cols].astype('float32')\n",
    "df[int_cols]   = df[int_cols].astype('int32')\n",
    "\n",
    "print(\"Memory usage after optimization:\")\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971350c",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Parse Transaction Timestamp & Derive Features\n",
    "**Purpose:** Convert string timestamp to datetime, extract hour/day features.\n",
    "**Why:** Time-of-day and weekday patterns can reveal fraud behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785e267",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 4\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9f2c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_ts</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             trans_ts  hour  dow\n",
       "0 2019-01-01 00:00:18     0    1\n",
       "1 2019-01-01 00:00:44     0    1\n",
       "2 2019-01-01 00:00:51     0    1\n",
       "3 2019-01-01 00:01:16     0    1\n",
       "4 2019-01-01 00:03:06     0    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse timestamp\n",
    "df['trans_ts'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "# Drop redundant columns\n",
    "df.drop(columns=['trans_date_trans_time', 'unix_time'], inplace=True)\n",
    "\n",
    "# Derive features\n",
    "df['hour'] = df['trans_ts'].dt.hour\n",
    "df['dow']  = df['trans_ts'].dt.dayofweek\n",
    "\n",
    "df[['trans_ts', 'hour', 'dow']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccbecb",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Drop Unnecessary ID/PII Columns\n",
    "**Purpose:** Remove columns that leak information or have no predictive value.\n",
    "**Why:** IDs and PII add noise or risk leakage but rarely generalize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba49216",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 5\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ae29bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['merchant', 'category', 'amt', 'gender', 'lat', 'long', 'city_pop',\n",
       "       'job', 'dob', 'merch_lat', 'merch_long', 'is_fraud', 'trans_ts', 'hour',\n",
       "       'dow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop card number, transaction ID, personal identifiers\n",
    "df.drop(columns=['Unnamed: 0','cc_num','trans_num','first','last','street','city','state','zip'], inplace=True)\n",
    "\n",
    "# Preview remaining columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae2c37",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Target Distribution (Class Imbalance)\n",
    "**Purpose:** Check fraud ratio to guide evaluation and sampling strategies.\n",
    "**Why:** Imbalanced classes require specialized metrics and handling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8403f94",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 6\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f7732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud cases fraction: 0.005789 (0.579% )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "0    1289169\n",
       "1       7506\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fraction of fraud cases\n",
    "fraud_ratio = df['is_fraud'].mean()\n",
    "print(f\"Fraud cases fraction: {fraud_ratio:.6f} ({fraud_ratio*100:.3f}% )\")\n",
    "df['is_fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863b4ce",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Data Types Overview\n",
    "**Purpose:** Verify each column's type to plan preprocessing.\n",
    "**Next:** Convert object types to appropriate categories or numerics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe899dfd",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 7\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04db7e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object            5\n",
       "float32           5\n",
       "int32             4\n",
       "datetime64[ns]    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215312a",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Missing Value Summary\n",
    "**Purpose:** Identify missing data proportions.\n",
    "**Next:** Plan imputation or column removal if too many NaNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7240d9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 8\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d279ace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "missing_pct = df.isna().mean().sort_values(ascending=False)\n",
    "print(missing_pct[missing_pct>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d7ef2",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Categorical Cardinality\n",
    "**Purpose:** Find high-cardinality columns to choose encoding strategy.\n",
    "**Next:** Low-card cols: one-hot; high-card: frequency/target encode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955f800",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 9\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e73603d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dob         968\n",
       "merchant    693\n",
       "job         494\n",
       "category     14\n",
       "gender        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "df[cat_cols].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfc691",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Basic Statistics & Outlier Detection\n",
    "**Purpose:** Summarize distributions, spot anomalies.\n",
    "**Next:** Winsorize or log-transform extreme outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c8faf1",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 10\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5110274f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merchant</th>\n",
       "      <td>1296675</td>\n",
       "      <td>693</td>\n",
       "      <td>fraud_Kilback LLC</td>\n",
       "      <td>4403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>1296675</td>\n",
       "      <td>14</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>131659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amt</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.351028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.65</td>\n",
       "      <td>47.52</td>\n",
       "      <td>83.139999</td>\n",
       "      <td>28948.900391</td>\n",
       "      <td>160.31604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1296675</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>709863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.537624</td>\n",
       "      <td>20.0271</td>\n",
       "      <td>34.620499</td>\n",
       "      <td>39.354301</td>\n",
       "      <td>41.940399</td>\n",
       "      <td>66.693298</td>\n",
       "      <td>5.075809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.226357</td>\n",
       "      <td>-165.672302</td>\n",
       "      <td>-96.797997</td>\n",
       "      <td>-87.476898</td>\n",
       "      <td>-80.157997</td>\n",
       "      <td>-67.950302</td>\n",
       "      <td>13.759077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_pop</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88824.440563</td>\n",
       "      <td>23.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2456.0</td>\n",
       "      <td>20328.0</td>\n",
       "      <td>2906700.0</td>\n",
       "      <td>301956.360689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>1296675</td>\n",
       "      <td>494</td>\n",
       "      <td>Film/video editor</td>\n",
       "      <td>9779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dob</th>\n",
       "      <td>1296675</td>\n",
       "      <td>968</td>\n",
       "      <td>1977-03-23</td>\n",
       "      <td>5636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merch_lat</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.537346</td>\n",
       "      <td>19.027784</td>\n",
       "      <td>34.733572</td>\n",
       "      <td>39.365681</td>\n",
       "      <td>41.957163</td>\n",
       "      <td>67.510269</td>\n",
       "      <td>5.109788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merch_long</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.226448</td>\n",
       "      <td>-166.671249</td>\n",
       "      <td>-96.897278</td>\n",
       "      <td>-87.438393</td>\n",
       "      <td>-80.236794</td>\n",
       "      <td>-66.950905</td>\n",
       "      <td>13.771091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_fraud</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.075863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_ts</th>\n",
       "      <td>1296675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-03 12:47:28.070214144</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2019-06-03 19:12:22.500000</td>\n",
       "      <td>2019-10-03 07:35:47</td>\n",
       "      <td>2020-01-28 15:02:55.500000</td>\n",
       "      <td>2020-06-21 12:13:37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.804858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.817824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>1296675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.070604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.198153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count unique                top    freq  \\\n",
       "merchant      1296675    693  fraud_Kilback LLC    4403   \n",
       "category      1296675     14      gas_transport  131659   \n",
       "amt         1296675.0    NaN                NaN     NaN   \n",
       "gender        1296675      2                  F  709863   \n",
       "lat         1296675.0    NaN                NaN     NaN   \n",
       "long        1296675.0    NaN                NaN     NaN   \n",
       "city_pop    1296675.0    NaN                NaN     NaN   \n",
       "job           1296675    494  Film/video editor    9779   \n",
       "dob           1296675    968         1977-03-23    5636   \n",
       "merch_lat   1296675.0    NaN                NaN     NaN   \n",
       "merch_long  1296675.0    NaN                NaN     NaN   \n",
       "is_fraud    1296675.0    NaN                NaN     NaN   \n",
       "trans_ts      1296675    NaN                NaN     NaN   \n",
       "hour        1296675.0    NaN                NaN     NaN   \n",
       "dow         1296675.0    NaN                NaN     NaN   \n",
       "\n",
       "                                     mean                  min  \\\n",
       "merchant                              NaN                  NaN   \n",
       "category                              NaN                  NaN   \n",
       "amt                             70.351028                  1.0   \n",
       "gender                                NaN                  NaN   \n",
       "lat                             38.537624              20.0271   \n",
       "long                           -90.226357          -165.672302   \n",
       "city_pop                     88824.440563                 23.0   \n",
       "job                                   NaN                  NaN   \n",
       "dob                                   NaN                  NaN   \n",
       "merch_lat                       38.537346            19.027784   \n",
       "merch_long                     -90.226448          -166.671249   \n",
       "is_fraud                         0.005789                  0.0   \n",
       "trans_ts    2019-10-03 12:47:28.070214144  2019-01-01 00:00:18   \n",
       "hour                            12.804858                  0.0   \n",
       "dow                              3.070604                  0.0   \n",
       "\n",
       "                                   25%                  50%  \\\n",
       "merchant                           NaN                  NaN   \n",
       "category                           NaN                  NaN   \n",
       "amt                               9.65                47.52   \n",
       "gender                             NaN                  NaN   \n",
       "lat                          34.620499            39.354301   \n",
       "long                        -96.797997           -87.476898   \n",
       "city_pop                         743.0               2456.0   \n",
       "job                                NaN                  NaN   \n",
       "dob                                NaN                  NaN   \n",
       "merch_lat                    34.733572            39.365681   \n",
       "merch_long                  -96.897278           -87.438393   \n",
       "is_fraud                           0.0                  0.0   \n",
       "trans_ts    2019-06-03 19:12:22.500000  2019-10-03 07:35:47   \n",
       "hour                               7.0                 14.0   \n",
       "dow                                1.0                  3.0   \n",
       "\n",
       "                                   75%                  max            std  \n",
       "merchant                           NaN                  NaN            NaN  \n",
       "category                           NaN                  NaN            NaN  \n",
       "amt                          83.139999         28948.900391      160.31604  \n",
       "gender                             NaN                  NaN            NaN  \n",
       "lat                          41.940399            66.693298       5.075809  \n",
       "long                        -80.157997           -67.950302      13.759077  \n",
       "city_pop                       20328.0            2906700.0  301956.360689  \n",
       "job                                NaN                  NaN            NaN  \n",
       "dob                                NaN                  NaN            NaN  \n",
       "merch_lat                    41.957163            67.510269       5.109788  \n",
       "merch_long                  -80.236794           -66.950905      13.771091  \n",
       "is_fraud                           0.0                  1.0       0.075863  \n",
       "trans_ts    2020-01-28 15:02:55.500000  2020-06-21 12:13:37            NaN  \n",
       "hour                              19.0                 23.0       6.817824  \n",
       "dow                                5.0                  6.0       2.198153  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0342e",
   "metadata": {},
   "source": [
    "## üîü Detailed Class Imbalance Analysis\n",
    "**Purpose:** Evaluate false negative vs false positive costs.\n",
    "**Next:** Plan SMOTE or class weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cfdeb",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 11\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd4bf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count     ratio\n",
      "is_fraud                   \n",
      "0         1289169  0.994211\n",
      "1            7506  0.005789\n"
     ]
    }
   ],
   "source": [
    "# Class counts & ratios\n",
    "counts = df['is_fraud'].value_counts()\n",
    "ratios = df['is_fraud'].value_counts(normalize=True)\n",
    "print(pd.concat([counts, ratios], axis=1, keys=['count','ratio']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd42ec",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Leakage Checks\n",
    "**Purpose:** Detect features that perfectly predict the target or leak future info.\n",
    "**Next:** Drop or re-engineer leaking features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b50794",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 12\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa530921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top numeric correlations with is_fraud:\n",
      "is_fraud      1.000000\n",
      "amt           0.219404\n",
      "hour          0.013799\n",
      "city_pop      0.002136\n",
      "lat           0.001894\n",
      "merch_lat     0.001741\n",
      "dow           0.001739\n",
      "merch_long    0.001721\n",
      "long          0.001721\n",
      "Name: is_fraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Only select numeric columns for correlation\n",
    "num_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Compute correlations with 'is_fraud'\n",
    "num_corr = df[num_cols].corr()['is_fraud'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top numeric correlations with is_fraud:\")\n",
    "print(num_corr.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08518720-bf71-4c93-9811-839b1c375eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Improved leakage checks for categorical columns\n",
    "# Find potential categorical leakage\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    unique_class_per_cat = df.groupby(col)['is_fraud'].nunique()\n",
    "    if unique_class_per_cat.max() == 1:\n",
    "        print(f\"‚ö†Ô∏è Potential leakage: '{col}' maps perfectly to a single fraud class\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fdc17f",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Duplicate Rows\n",
    "**Purpose:** Remove exact duplicates that can skew training.\n",
    "**Next:** Drop duplicates if found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d0e7a",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 13\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21652320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "dup_count = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {dup_count}\")\n",
    "if dup_count > 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicates dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662eb126",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Time Order & Concept Drift\n",
    "**Purpose:** Ensure chronological order and detect drift between early vs late transactions.\n",
    "**Next:** Use time-based CV or retrain triggers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5dd6c",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 14\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5010696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by transaction time\n",
    "df.sort_values('trans_ts', inplace=True)\n",
    "\n",
    "# Train-test split by time\n",
    "split_date = df['trans_ts'].quantile(0.8)\n",
    "train = df[df['trans_ts'] < split_date]\n",
    "test  = df[df['trans_ts'] >= split_date]\n",
    "\n",
    "# Compute PSI for 'amt_log' if exists\n",
    "if 'amt_log' in df.columns:\n",
    "    import numpy as np\n",
    "    def psi(expected, actual, bins=10):\n",
    "        def _bin(x, edges): return np.digitize(x, edges[:-1])\n",
    "        edges = np.histogram(expected, bins=bins)[1]\n",
    "        e_perc = np.bincount(_bin(expected, edges), minlength=bins) / len(expected)\n",
    "        a_perc = np.bincount(_bin(actual, edges), minlength=bins) / len(actual)\n",
    "        return np.sum((a_perc - e_perc) * np.log((a_perc + 1e-6)/(e_perc + 1e-6)))\n",
    "    psi_val = psi(train['amt_log'], test['amt_log'])\n",
    "    print(f\"PSI for amt_log: {psi_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f2670c",
   "metadata": {},
   "source": [
    "## üíæ Save Cleaned Data\n",
    "**Purpose:** Persist the cleaned and enriched dataset for modeling steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e02b9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 15\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6831511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'cc_fraud_cleaned.parquet'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.to_parquet(r'/Users/shiva/PycharmProjects/mlearn_poc/dailyprojects/project8/cc_fraud_cleaned.parquet', index=False)\n",
    "print(\"Cleaned data saved to 'cc_fraud_cleaned.parquet'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550e484",
   "metadata": {},
   "source": [
    "## üåü Feature Engineering Steps\n",
    "**Purpose:** Transform raw cleaned data into model-ready features.\n",
    "Each section below creates or encodes features for the fraud detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371e44c",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Handle Missing Values\n",
    "**What to do:** Impute or drop missing data.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f79e3",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 16\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d23e362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values if present (example: none expected)\n",
    "# Numeric: median, Categorical: mode or 'Unknown'\n",
    "for col in df.columns:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        if df[col].dtype in ['float32','float64','int32','int64']:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna('Unknown', inplace=True)\n",
    "print(\"Missing values after imputation:\", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c956e",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Encoding Categorical Variables\n",
    "**What to do:** Convert categories into numeric representations.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0929dc",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 17\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a1f78f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>dob</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>trans_ts</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_home</th>\n",
       "      <th>cat_kids_pets</th>\n",
       "      <th>cat_misc_net</th>\n",
       "      <th>cat_misc_pos</th>\n",
       "      <th>cat_personal_care</th>\n",
       "      <th>cat_shopping_net</th>\n",
       "      <th>cat_shopping_pos</th>\n",
       "      <th>cat_travel</th>\n",
       "      <th>merchant_freq</th>\n",
       "      <th>job_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.970000</td>\n",
       "      <td>36.078800</td>\n",
       "      <td>-81.178101</td>\n",
       "      <td>3495</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>36.011292</td>\n",
       "      <td>-82.048317</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.230003</td>\n",
       "      <td>48.887798</td>\n",
       "      <td>-118.210503</td>\n",
       "      <td>149</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>49.159046</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.003932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.110001</td>\n",
       "      <td>42.180801</td>\n",
       "      <td>-112.262001</td>\n",
       "      <td>4154</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>43.150703</td>\n",
       "      <td>-112.154480</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>46.230598</td>\n",
       "      <td>-112.113800</td>\n",
       "      <td>1939</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>47.034332</td>\n",
       "      <td>-112.561073</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.001951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.959999</td>\n",
       "      <td>38.420700</td>\n",
       "      <td>-79.462898</td>\n",
       "      <td>99</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632462</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.001556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          amt        lat        long  city_pop         dob  merch_lat  \\\n",
       "0    4.970000  36.078800  -81.178101      3495  1988-03-09  36.011292   \n",
       "1  107.230003  48.887798 -118.210503       149  1978-06-21  49.159046   \n",
       "2  220.110001  42.180801 -112.262001      4154  1962-01-19  43.150703   \n",
       "3   45.000000  46.230598 -112.113800      1939  1967-01-12  47.034332   \n",
       "4   41.959999  38.420700  -79.462898        99  1986-03-28  38.674999   \n",
       "\n",
       "   merch_long  is_fraud            trans_ts  hour  ...  cat_home  \\\n",
       "0  -82.048317         0 2019-01-01 00:00:18     0  ...     False   \n",
       "1 -118.186462         0 2019-01-01 00:00:44     0  ...     False   \n",
       "2 -112.154480         0 2019-01-01 00:00:51     0  ...     False   \n",
       "3 -112.561073         0 2019-01-01 00:01:16     0  ...     False   \n",
       "4  -78.632462         0 2019-01-01 00:03:06     0  ...     False   \n",
       "\n",
       "   cat_kids_pets  cat_misc_net  cat_misc_pos  cat_personal_care  \\\n",
       "0          False          True         False              False   \n",
       "1          False         False         False              False   \n",
       "2          False         False         False              False   \n",
       "3          False         False         False              False   \n",
       "4          False         False          True              False   \n",
       "\n",
       "   cat_shopping_net  cat_shopping_pos  cat_travel  merchant_freq  job_freq  \n",
       "0             False             False       False       0.000977  0.002734  \n",
       "1             False             False       False       0.001930  0.003932  \n",
       "2             False             False       False       0.001461  0.000394  \n",
       "3             False             False       False       0.002015  0.001951  \n",
       "4             False             False       False       0.001228  0.001556  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Binary encoding for gender\n",
    "df['gender_enc'] = LabelEncoder().fit_transform(df['gender'])\n",
    "\n",
    "# One-hot for low-cardinality 'category'\n",
    "df = pd.concat([df, pd.get_dummies(df['category'], prefix='cat', drop_first=True)], axis=1)\n",
    "df.drop(columns=['gender','category'], inplace=True)\n",
    "\n",
    "# Frequency encoding for 'merchant' and 'job'\n",
    "for col in ['merchant','job']:\n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    df[f'{col}_freq'] = df[col].map(freq)\n",
    "    df.drop(columns=[col], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d884aa4",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Log Transform Skewed Numeric Features\n",
    "**What to do:** Reduce skew in monetary features.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7edf6",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 18\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d2f48e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness amt_log: -0.2988528\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Log transform amount\n",
    "df['amt_log'] = np.log1p(df['amt'])\n",
    "df.drop(columns=['amt'], inplace=True)\n",
    "\n",
    "# Check skew\n",
    "print(\"Skewness amt_log:\", df['amt_log'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e30e8f",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Interaction & Polynomial Features\n",
    "**What to do:** Capture nonlinear relationships.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26aacb",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 19\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6822f04b-c162-4204-9dd9-674fab6be5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine_vectorized(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# Compute distance column\n",
    "df['dist_km'] = haversine_vectorized(df['lat'], df['long'], df['merch_lat'], df['merch_long'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a65e074c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt_dist</th>\n",
       "      <th>amt_log_sq</th>\n",
       "      <th>dist_km_sq</th>\n",
       "      <th>age_sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.433823</td>\n",
       "      <td>3.192464</td>\n",
       "      <td>6177.566406</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141.521896</td>\n",
       "      <td>21.942278</td>\n",
       "      <td>912.778870</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>584.167908</td>\n",
       "      <td>29.145533</td>\n",
       "      <td>11708.558594</td>\n",
       "      <td>3136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366.300781</td>\n",
       "      <td>14.658495</td>\n",
       "      <td>9153.481445</td>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291.632782</td>\n",
       "      <td>14.139626</td>\n",
       "      <td>6014.987305</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amt_dist  amt_log_sq    dist_km_sq  age_sq\n",
       "0  140.433823    3.192464   6177.566406     900\n",
       "1  141.521896   21.942278    912.778870    1600\n",
       "2  584.167908   29.145533  11708.558594    3136\n",
       "3  366.300781   14.658495   9153.481445    2704\n",
       "4  291.632782   14.139626   6014.987305    1024"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dob to datetime if not already\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "\n",
    "# Calculate age at the time of transaction\n",
    "df['age'] = (df['trans_ts'] - df['dob']).dt.days // 365\n",
    "\n",
    "df['amt_dist'] = df['amt_log'] * df['dist_km']\n",
    "\n",
    "for col in ['amt_log', 'dist_km', 'age']:\n",
    "    df[f'{col}_sq'] = df[col] ** 2\n",
    "\n",
    "df[['amt_dist','amt_log_sq','dist_km_sq','age_sq']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb97fa",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Feature Scaling\n",
    "**What to do:** Standardize features for linear models or distance-based methods.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c3295",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 20\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4edf5dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt_log</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>age</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>amt_dist</th>\n",
       "      <th>amt_log_sq</th>\n",
       "      <th>dist_km_sq</th>\n",
       "      <th>age_sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.354630</td>\n",
       "      <td>0.085272</td>\n",
       "      <td>-0.891968</td>\n",
       "      <td>-1.878145</td>\n",
       "      <td>-0.941975</td>\n",
       "      <td>-0.874065</td>\n",
       "      <td>-1.240065</td>\n",
       "      <td>-0.106785</td>\n",
       "      <td>-0.816524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.892466</td>\n",
       "      <td>-1.576486</td>\n",
       "      <td>-0.317551</td>\n",
       "      <td>-1.878145</td>\n",
       "      <td>-0.941975</td>\n",
       "      <td>-0.866661</td>\n",
       "      <td>0.882223</td>\n",
       "      <td>-1.319286</td>\n",
       "      <td>-0.429255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.446503</td>\n",
       "      <td>1.102158</td>\n",
       "      <td>0.601517</td>\n",
       "      <td>-1.878145</td>\n",
       "      <td>-0.941975</td>\n",
       "      <td>2.145548</td>\n",
       "      <td>1.697558</td>\n",
       "      <td>1.167024</td>\n",
       "      <td>0.420524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.228913</td>\n",
       "      <td>0.671746</td>\n",
       "      <td>0.371750</td>\n",
       "      <td>-1.878145</td>\n",
       "      <td>-0.941975</td>\n",
       "      <td>0.662961</td>\n",
       "      <td>0.057773</td>\n",
       "      <td>0.578580</td>\n",
       "      <td>0.181524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.175889</td>\n",
       "      <td>0.049514</td>\n",
       "      <td>-0.777085</td>\n",
       "      <td>-1.878145</td>\n",
       "      <td>-0.941975</td>\n",
       "      <td>0.154845</td>\n",
       "      <td>-0.000958</td>\n",
       "      <td>-0.144227</td>\n",
       "      <td>-0.747922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amt_log   dist_km       age      hour       dow  amt_dist  amt_log_sq  \\\n",
       "0 -1.354630  0.085272 -0.891968 -1.878145 -0.941975 -0.874065   -1.240065   \n",
       "1  0.892466 -1.576486 -0.317551 -1.878145 -0.941975 -0.866661    0.882223   \n",
       "2  1.446503  1.102158  0.601517 -1.878145 -0.941975  2.145548    1.697558   \n",
       "3  0.228913  0.671746  0.371750 -1.878145 -0.941975  0.662961    0.057773   \n",
       "4  0.175889  0.049514 -0.777085 -1.878145 -0.941975  0.154845   -0.000958   \n",
       "\n",
       "   dist_km_sq    age_sq  \n",
       "0   -0.106785 -0.816524  \n",
       "1   -1.319286 -0.429255  \n",
       "2    1.167024  0.420524  \n",
       "3    0.578580  0.181524  \n",
       "4   -0.144227 -0.747922  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scale_cols = ['amt_log','dist_km','age','hour','dow','amt_dist','amt_log_sq','dist_km_sq','age_sq']\n",
    "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "\n",
    "df[scale_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ceeb64",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Feature Matrix\n",
    "**Purpose:** Review final columns and prepare X, y for modeling.\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921be7a9",
   "metadata": {},
   "source": [
    "### üß† Thought Process for Cell 21\n",
    "**What I'm checking / Why**:  \n",
    "- *Goal*: Describe the primary purpose of this cell (e.g., load data, cast dtypes).  \n",
    "- *Expectation*: What a 'healthy' output looks like (shape, memory, etc.).  \n",
    "\n",
    "**What I look for in the output**:  \n",
    "- Key flags (null counts, skew, imbalance, leakage signals).  \n",
    "\n",
    "**Typical next actions**:  \n",
    "- If results are normal ‚Üí proceed.  \n",
    "- If anomalies appear ‚Üí how I'd fix (impute, drop, transform).  \n",
    "\n",
    "**Pros / Cons & Alternatives**:  \n",
    "- Why I chose this method vs alternatives.  \n",
    "- Potential drawbacks or edge‚Äëcases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10b240ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (1296675, 26)\n",
      "Features: ['city_pop', 'hour', 'dow', 'gender_enc', 'cat_food_dining', 'cat_gas_transport', 'cat_grocery_net', 'cat_grocery_pos', 'cat_health_fitness', 'cat_home', 'cat_kids_pets', 'cat_misc_net', 'cat_misc_pos', 'cat_personal_care', 'cat_shopping_net', 'cat_shopping_pos', 'cat_travel', 'merchant_freq', 'job_freq', 'amt_log', 'dist_km', 'amt_dist', 'amt_log_sq', 'dist_km_sq', 'age', 'age_sq']\n"
     ]
    }
   ],
   "source": [
    "# Drop any remaining raw columns if needed\n",
    "# Prepare X and y\n",
    "X = df.drop(columns=['trans_ts','is_fraud','lat','long','merch_lat','merch_long','dob'])\n",
    "y = df['is_fraud']\n",
    "print(\"Final feature matrix shape:\", X.shape)\n",
    "print(\"Features:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3a8dc-a395-4c74-b69c-2f62654bb775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
